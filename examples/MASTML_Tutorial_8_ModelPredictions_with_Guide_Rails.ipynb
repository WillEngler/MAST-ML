{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEuScQa-YTxH"
   },
   "source": [
    "# Welcome to the eighth MAST-ML tutorial notebook,\n",
    "\n",
    "# Model predictions with guide rails with MAST-ML!\n",
    "\n",
    "## In this notebook, we will learn how to perform simple checks on our test data:\n",
    "\n",
    "1. [Set up MAST-ML on Colab and begin session](#task1)\n",
    "2. [Fit models and check elemental spaces](#task2)\n",
    "3. [Fit models and check Gaussian Process Error Bars](#task3)\n",
    "4. [Fit models and check Domain with MADML](#task4)\n",
    "5. [Fit models and predict Domain](#task5)\n",
    "\n",
    "We need to first install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAaWiiqccj0Z"
   },
   "source": [
    "## Task 1: Set up MAST-ML on Colab and begin session <a name=\"task1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3s7adwqvUvzm"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/uw-cmg/MAST-ML/@dev_lane\n",
    "!pip install pyyaml==5.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHnQfNrgY3Uu"
   },
   "source": [
    "Mount Google Drive to save output from runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0enGVD7QVO4G"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHJq2q2fZCRD"
   },
   "source": [
    "Import needed packages and subroutines for running example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eM1p76gW2Yt"
   },
   "outputs": [],
   "source": [
    "from mastml.mastml import Mastml\n",
    "from mastml.datasets import LocalDatasets\n",
    "from mastml.models import SklearnModel, EnsembleModel\n",
    "from mastml.preprocessing import SklearnPreprocessor\n",
    "from mastml.data_splitters import SklearnDataSplitter, NoSplit, LeaveOutPercent\n",
    "from mastml.feature_selectors import EnsembleModelFeatureSelector\n",
    "from mastml.mastml_predictor import make_prediction\n",
    "from pathlib import Path\n",
    "import mastml\n",
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "try:\n",
    "    data_path = os.path.join(mastml.__path__._path[0], 'data')\n",
    "except:\n",
    "    data_path = os.path.join(mastml.__path__[0], 'data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzqT3_kEZF58"
   },
   "source": [
    "Define the path to save data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrBExmXsW6-F"
   },
   "outputs": [],
   "source": [
    "SAVEPATH = 'drive/MyDrive/MASTML_tutorial_8_ModelPredictions_with_Guide_Rails'\n",
    "\n",
    "mastml_instance = Mastml(savepath=SAVEPATH)\n",
    "savepath = mastml_instance.get_savepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LT_CrB5rZIS6"
   },
   "source": [
    "Load the standard diffusion dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcUd8ESJXrX-"
   },
   "outputs": [],
   "source": [
    "target = 'E_regression'\n",
    "\n",
    "extra_columns = ['Material compositions 1', 'Material compositions 2', 'Hop activation barrier']\n",
    "d = LocalDatasets(file_path=data_path+'/diffusion_data_allfeatures.xlsx',\n",
    "                  target=target,\n",
    "                  extra_columns=extra_columns,\n",
    "                  group_column='Material compositions 1',\n",
    "                  testdata_columns=None,\n",
    "                  as_frame=True)\n",
    "\n",
    "# Load the data with the load_data() method\n",
    "data_dict = d.load_data()\n",
    "\n",
    "# Let's assign each data object to its respective name\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "X_extra = data_dict['X_extra']\n",
    "groups = data_dict['groups']\n",
    "X_testdata = data_dict['X_testdata']\n",
    "\n",
    "metrics = [\n",
    "           'r2_score',\n",
    "           'mean_absolute_error',\n",
    "           'root_mean_squared_error',\n",
    "           'rmse_over_stdev',\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvwP116Dcrxa"
   },
   "source": [
    "## Task 2: Fit models and check elemental spaces <a name=\"task1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPUKH1kyZPGN"
   },
   "source": [
    "Setup machine learning which checks if an element from a test set was observed within the training set. If all elements from the test set are observed in the training set, the case is marked as \"in_domain\". If only some elements from the test set are observed in training data, then the case is marked as \"maybe_in_domain\". If none of the test elements are observed within training data, then the case is flagged as \"out_of_domain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cy2nvl13X86O"
   },
   "outputs": [],
   "source": [
    "preprocessor = SklearnPreprocessor(\n",
    "                                   preprocessor='StandardScaler',\n",
    "                                   as_frame=True,\n",
    "                                   )\n",
    "\n",
    "model = SklearnModel(model='RandomForestRegressor')\n",
    "\n",
    "splitter = SklearnDataSplitter(\n",
    "                               splitter='RepeatedKFold',\n",
    "                               n_repeats=10,\n",
    "                               n_splits=5,\n",
    "                               )\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[('elemental', groups)],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-K4ILEEZuHG"
   },
   "source": [
    "Here we use the error bars inherently in Gaussian Process Regression (GPR) to determine if we should flag a case as worrisome. Through 5-fold cross validation, we attain the maximum uncertainty from GPR and compare to tets cases. If the test case unceratinty is grater than the maximum training uncertainty, we mark the observation as \"out_of_domain\" and \"in_domain\" otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gce-RKGWc2c4"
   },
   "source": [
    "## Task 3: Fit models and check Gaussian Process Error Bars <a name=\"task1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SvERU85YBa9"
   },
   "outputs": [],
   "source": [
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=['gpr'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7uRLlgb0sPM"
   },
   "source": [
    "## Task 4: Fit models and check domain with MADML  <a name=\"task4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2ZyDX3C0sPM"
   },
   "source": [
    "Fit the kinds of models that we need for domain evaluation. We use the bare minimum inputs here and mostly use default parameters. Keep in mind that feature selection may be needed for good results using the MADML package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iL0UMRyR0sPM"
   },
   "outputs": [],
   "source": [
    "splitter = NoSplit()\n",
    "\n",
    "params = {'n_repeats': 1}  # Increase if more averaging needed for convergence\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a specific linear uncerintaty model with their coefficients here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_repeats': 1}  # Increase if more averaging needed for convergence\n",
    "params['uq_coeffs'] = [0.0, 2.0, 0.1]  # Starting guess for coefficients in c0+c1*x+c2*x^2+...+cn*x^n\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we do not want to modify the uncertainty model coefficients. We can bass the specific functions for the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_repeats': 1}  # Increase if more averaging needed for convergence\n",
    "params['uq_function'] = lambda x: 0.7+1.05*x  # Note that this is fixed across folds\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also alter the number of clusters used in agglomerative clustering to make our splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_repeats': 1}  # Increase if more averaging needed for convergence\n",
    "params['n_clusters'] = [2, 3, 4]  # A list of the number of clusters in each split\n",
    "\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the ground truth for our domain tests. Note that we can also combine parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_repeats': 1}  # Increase if more averaging needed for convergence\n",
    "params['gt_residual'] = 0.75  # Ground truth for residual test\n",
    "params['gt_uncertainty'] = 0.5  # Ground truth for uncertainty test\n",
    "\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the number of bins used for our uncertainty test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_repeats': 1}  # Increase if more averaging needed for convergence\n",
    "params['bins'] = 5\n",
    "\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel parameters can also be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_repeats': 1}  # Increase if more averaging needed for convergence\n",
    "params['bandwidth'] = 1.5\n",
    "params['kernel'] = 'gaussian'\n",
    "\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now clean our work space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = glob.glob('Ran*')\n",
    "for d in to_delete:\n",
    "    subprocess.run(['rm', '-rf', d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Fit models and predict Domain <a name=\"task5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we fit both GPR and MADML domain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = NoSplit()\n",
    "\n",
    "params = {'n_repeats': 2}  # Increase if more averaging needed for convergence\n",
    "domain = ('madml', params)\n",
    "\n",
    "splitter.evaluate(\n",
    "                  X=X,\n",
    "                  y=y,\n",
    "                  models=[model],\n",
    "                  preprocessor=preprocessor,\n",
    "                  metrics=metrics,\n",
    "                  plots=['Scatter', 'Histogram'],\n",
    "                  X_extra=X_extra,\n",
    "                  verbosity=3,\n",
    "                  domain=[domain, 'gpr'],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZBSJry20sPM"
   },
   "source": [
    "Use fitted models and predict on sample data. Here we predict on the data we train on, but can be anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hzA6s98o0sPN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       y_pred     y_err  domain_gpr  Residual for 0.95  Residual for Max F1   \n",
      "0   -0.003191  0.051607          -1                  0                    1  \\\n",
      "1    0.064101  0.224702          -1                  1                    1   \n",
      "2    0.264911  0.115056          -1                  1                    1   \n",
      "3   -0.042670  0.069718          -1                  0                    1   \n",
      "4    0.258767  0.131331          -1                  1                    1   \n",
      "..        ...       ...         ...                ...                  ...   \n",
      "403 -0.022099  0.145523          -1                  0                    1   \n",
      "404  0.143181  0.229243          -1                  0                    1   \n",
      "405  0.211635  0.152288          -1                  0                    1   \n",
      "406  0.185900  0.103158          -1                  0                    1   \n",
      "407  0.161902  0.169626          -1                  0                    1   \n",
      "\n",
      "     Uncertainty for 0.95  Uncertainty for Max F1      dist  \n",
      "0                       0                       0  0.884227  \n",
      "1                       1                       1  0.251691  \n",
      "2                       1                       1  0.283408  \n",
      "3                       0                       0  0.727743  \n",
      "4                       1                       1  0.257772  \n",
      "..                    ...                     ...       ...  \n",
      "403                     0                       0  0.816549  \n",
      "404                     0                       0  0.820780  \n",
      "405                     0                       0  0.800442  \n",
      "406                     0                       0  0.919245  \n",
      "407                     0                       0  0.934091  \n",
      "\n",
      "[408 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "file_to_move = glob.glob('Ran*')[0]\n",
    "subprocess.run(['mv', file_to_move, 'output'])\n",
    "path_fullfit = './output/split_0'\n",
    "\n",
    "model_path = os.path.join(path_fullfit, 'RandomForestRegressor.pkl')\n",
    "preprocessor_path = os.path.join(path_fullfit, 'StandardScaler.pkl')\n",
    "domain_path = list(map(str, Path(path_fullfit).rglob('domain_*.pkl')))\n",
    "\n",
    "pred_df = make_prediction(\n",
    "                          X_train=X,\n",
    "                          y_train=y,\n",
    "                          X_test=X,\n",
    "                          model=model_path,\n",
    "                          preprocessor=preprocessor_path,\n",
    "                          domain=domain_path,\n",
    "                          )\n",
    "\n",
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhXILwDs0sPN"
   },
   "source": [
    "We can also change the default thresholds for prediction and add our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rNSWvcUD0sPN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       y_pred     y_err  domain_gpr  Residual for 0.75  Uncertainty for 0.2   \n",
      "0   -0.003191  0.051607          -1                  0                    0  \\\n",
      "1    0.064101  0.224702          -1                  1                    0   \n",
      "2    0.264911  0.115056          -1                  1                    0   \n",
      "3   -0.042670  0.069718          -1                  1                    0   \n",
      "4    0.258767  0.131331          -1                  1                    0   \n",
      "..        ...       ...         ...                ...                  ...   \n",
      "403 -0.022099  0.145523          -1                  0                    0   \n",
      "404  0.143181  0.229243          -1                  0                    0   \n",
      "405  0.211635  0.152288          -1                  0                    0   \n",
      "406  0.185900  0.103158          -1                  0                    0   \n",
      "407  0.161902  0.169626          -1                  0                    0   \n",
      "\n",
      "         dist  \n",
      "0    0.884227  \n",
      "1    0.251691  \n",
      "2    0.283408  \n",
      "3    0.727743  \n",
      "4    0.257772  \n",
      "..        ...  \n",
      "403  0.816549  \n",
      "404  0.820780  \n",
      "405  0.800442  \n",
      "406  0.919245  \n",
      "407  0.934091  \n",
      "\n",
      "[408 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "thresholds = [('residual', 0.75), ('uncertainty', 0.2)]\n",
    "\n",
    "pred_df = make_prediction(\n",
    "                          X_train=X,\n",
    "                          y_train=y,\n",
    "                          X_test=X,\n",
    "                          model=model_path,\n",
    "                          preprocessor=preprocessor_path,\n",
    "                          domain=domain_path,\n",
    "                          madml_thresholds=thresholds\n",
    "                          )\n",
    "\n",
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
